{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eBay Web Scraping\n",
    "# Jing Hao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "import json\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Write a program that accesses all trivia results for the numbers from 0 (zero) to 99 using batch requests only (One single query for all the numbers). Print the output result to the screen in the format of [3-digit number with leading zeros] - [TRIVIA] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceurl = \"http://numbersapi.com/\"\n",
    "number = \"0..99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the url to get data\n",
    "url = serviceurl + number\n",
    "# get and open url\n",
    "uh = urllib.request.urlopen(url)\n",
    "# read data\n",
    "data = uh.read()\n",
    "# load data using json\n",
    "json_data=json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to print json data in required format\n",
    "def print_json(json_data):\n",
    "    for key in list(json_data.keys()):\n",
    "        print(f\"{str(key).zfill(3)} - {json_data[key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Web-scraping: Which sellers advertise/sponsor on eBay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTxt(filename, file_content):\n",
    "    with open(filename + \".txt\", \"w\") as f:\n",
    "        for row in file_content:\n",
    "            f.write(row + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebay_url = \"https://www.ebay.com/sch/i.html?_from=R40&_nkw=playstation+4+slim&_sacat=0&rt=nc&LH_BIN=1&_ipg=100\"\n",
    "html = urllib.request.urlopen(ebay_url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the url pattern that determine the page number\n",
    "page_pat = \"&_pgn=\"\n",
    "# Set the Sponsored pattern\n",
    "pattern = \".*S.*P.*O.*N.*S.*O.*R.*E.*D\"\n",
    "# create the list to store the sponsored and non-sponsored links for ten pages\n",
    "tenPage_sponsored = []\n",
    "tenPage_non_sponsored = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    # get the url for the ith page\n",
    "    new_url = ebay_url + page_pat + str(i)\n",
    "    # get the content of ith page\n",
    "    html_content = urllib.request.urlopen(new_url).read()\n",
    "    # store the page content in 'soup'\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # create lists to store the urls of the sponsored and non-sponsored items in this page\n",
    "    singlePage_sponsored = []\n",
    "    singlePage_non_sponsored = []\n",
    "    # class .s-item__link store item information\n",
    "    # get the infomation of all items\n",
    "    items = soup.select(\"#srp-river-results > ul > li.s-item\")\n",
    "    \n",
    "    for item in items:\n",
    "        a = item.find(\"a\")\n",
    "        if not a:\n",
    "            continue\n",
    "        txt = item.find(\"span\").get_text()\n",
    "        result = bool(re.search(pattern, txt))\n",
    "        link = a['href']\n",
    "    \n",
    "        # to determine if it is sponsored\n",
    "        if (result == True):\n",
    "            link_sponsored = link\n",
    "            # append the link of sponsored item in this page\n",
    "            singlePage_sponsored.append(link_sponsored)\n",
    "        else:\n",
    "            link_non_sponsored = link\n",
    "            # append the link of non-sponsored item in this page\n",
    "            singlePage_non_sponsored.append(link_non_sponsored)\n",
    "    \n",
    "    # append the links of sponsored and non-sponsored items in each page to a list\n",
    "    tenPage_sponsored += singlePage_sponsored   \n",
    "    tenPage_non_sponsored += singlePage_non_sponsored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save urls to corresponding folders\n",
    "sponsored = 'sponsored'\n",
    "non_sponsored = 'non-sponsored'\n",
    "saveTxt(sponsored, tenPage_sponsored)\n",
    "saveTxt(non_sponsored, tenPage_non_sponsored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create the folder\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the folder\n",
    "createFolder('./sponsored/')\n",
    "createFolder('./non_sponsored/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save urls in a txt file respectively\n",
    "\n",
    "sponsored_url = []\n",
    "non_sponsored_url = []\n",
    "\n",
    "with open('sponsored.txt') as sponsored:\n",
    "    for line in sponsored:\n",
    "        sponsored_url.append(line.rstrip('\\n'))\n",
    "        \n",
    "with open('non-sponsored.txt') as non_sponsored:\n",
    "    for line in non_sponsored:\n",
    "        non_sponsored_url.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in sponsored_url:\n",
    "    html_content = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    \n",
    "    # find all sponsored products' id \n",
    "    prodDetail = soup.find('div', {'class': 'prodDetailSec'})\n",
    "    if not prodDetail:\n",
    "        continue\n",
    "    prodId_txt = prodDetail.find('td', text = 'eBay Product ID (ePID)')\n",
    "    prodId = prodId_txt.findNext('td').text.strip()\n",
    "    \n",
    "    # save the html content and name the file using product id\n",
    "    save_path = './sponsored/'\n",
    "    completeName = os.path.join(save_path, prodId + \".html\")\n",
    "    with open(completeName , \"wb\") as f:\n",
    "        f.write(html_content)\n",
    "        f.close()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in non_sponsored_url:\n",
    "    html_content = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    \n",
    "    # find all non-sponsorod products' id\n",
    "    prodDetail = soup.find('div', {'class': 'prodDetailSec'})\n",
    "    if not prodDetail:\n",
    "        continue\n",
    "    prodId_txt = prodDetail.find('td', text = 'eBay Product ID (ePID)')\n",
    "    prodId = prodId_txt.findNext('td').text.strip()\n",
    "    \n",
    "    # save the html content and name the file using product id\n",
    "    save_path = './non_sponsored/'\n",
    "    completeName = os.path.join(save_path, prodId + \".html\")\n",
    "    with open(completeName , \"wb\") as f:\n",
    "        f.write(html_content)\n",
    "        f.close()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web scraping to find all the info\n",
    "seller_name_list = []\n",
    "seller_score_list = []\n",
    "item_price_list = []\n",
    "qty_sold_list = []\n",
    "best_offer_available_list = []\n",
    "title_list = []\n",
    "returns_allowed_list = []\n",
    "shipping_computed_list = []\n",
    "condition_list = []\n",
    "sponsor_list = []\n",
    "\n",
    "folders = ['./sponsored/', './non_sponsored/']\n",
    "for folder in folders:\n",
    "    folder_list = os.listdir(folder)\n",
    "\n",
    "    for file in folder_list:\n",
    "        if not file.endswith('html'):\n",
    "            continue\n",
    "        fname = os.path.join(folder,file)\n",
    "        html_file_content = open(fname, 'r', encoding = 'utf-8').read()\n",
    "        soup_all = BeautifulSoup(html_file_content, 'html.parser')\n",
    "        \n",
    "        ### find seller name\n",
    "        seller = soup_all.find('div',{'class':'mbg vi-VR-margBtm3'}).a.span.text\n",
    "        seller_name_list.append(seller)\n",
    "        \n",
    "        ### find seller score\n",
    "        if not soup_all.find('a', {'class': 'reviews-star-rating'}):\n",
    "            score = None\n",
    "        else:\n",
    "            score = soup_all.find('a', {'class': 'reviews-star-rating'}).attrs['aria-label'].split()[0]\n",
    "        seller_score_list.append(score)\n",
    "        \n",
    "        ### find item price\n",
    "        if not soup_all.find('span', {'id': 'prcIsum'}):\n",
    "            item_price = soup_all.find('span', {'id': 'mm-saleDscPrc'}).attrs['content']\n",
    "        else: \n",
    "            item_price = soup_all.find('span', {'id': 'prcIsum'}).attrs['content']\n",
    "        item_price_list.append(item_price)\n",
    "        \n",
    "        ### find # of items sold\n",
    "        if not soup_all.find('a', {'class': 'vi-txt-underline'}):\n",
    "            qty = None\n",
    "        else:\n",
    "            qty = soup_all.find('a', {'class': 'vi-txt-underline'}).text.replace(',', '').split()[0]\n",
    "        qty_sold_list.append(qty)\n",
    "\n",
    "        ### find best offer available or not\n",
    "        if not soup_all.find('div', {'class': 'vi-bbox-dspn u-flL lable boLable'}):\n",
    "            best_offer = 'NO'\n",
    "        else: best_offer = 'YES'\n",
    "        best_offer_available_list.append(best_offer)\n",
    "        \n",
    "        ### find product title\n",
    "        title = soup_all.find('h1', {'class': 'it-ttl'}).text\n",
    "        title_split = re.split(r'\\s{2,}', title)[1]\n",
    "        title_list.append(title_split)\n",
    "\n",
    "        ### find if return is allowed\n",
    "        returns_txt = soup_all.find('span', {'id': 'vi-ret-accrd-txt'}).text\n",
    "        if returns_txt == 'Seller does not accept returns':\n",
    "            returns = 'NO'\n",
    "        else:\n",
    "            returns = 'YES'\n",
    "        returns_allowed_list.append(returns)\n",
    "\n",
    "        ### find if shipping cost is computed using zip or not\n",
    "        if not soup_all.find('input', {'id': 'shGetRates'}):\n",
    "            shipping_computed = 'NO'\n",
    "        else:\n",
    "            shipping_computed = 'YES'\n",
    "        shipping_computed_list.append(shipping_computed)\n",
    "\n",
    "        ### find product condition\n",
    "        condition = soup_all.find('div', {'id': 'vi-itm-cond'}).text\n",
    "        condition_list.append(condition)\n",
    "\n",
    "        ### lable if the product is sponsored or not\n",
    "        if folder == './sponsored/':   \n",
    "            sponsor = ['YES']\n",
    "        else:\n",
    "            sponsor = ['NO'] \n",
    "        sponsor_list += sponsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to correct format\n",
    "\n",
    "seller_scores = []\n",
    "for score in seller_score_list:\n",
    "    if score != None:\n",
    "        score_float = float(score)\n",
    "    else:\n",
    "        score_float = None\n",
    "    seller_scores.append(score_float)\n",
    "\n",
    "item_price_float = []\n",
    "item_prices = []\n",
    "for price in item_price_list:\n",
    "    item_price_float.append(float(price))\n",
    "for price_float in item_price_float:\n",
    "    dollar_cent = int(price_float*100)\n",
    "    item_prices.append(dollar_cent)\n",
    "    \n",
    "qty_sold = []\n",
    "for qty in qty_sold_list:\n",
    "    if qty != None:\n",
    "        qty_int = int(qty)\n",
    "    else: \n",
    "        qty_int = None\n",
    "    qty_sold.append(qty_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to SQL. Create a database and name it \"eBay\". Save the information into a single table named \"eBay_items\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to SQLite3 and create a database named \"eBay.db\"\n",
    "connection = sqlite3.connect('eBay.db')\n",
    "cursor = connection.cursor()\n",
    "# create sql query to create table \"eBay_items\"\n",
    "create_table = \"\"\"CREATE TABLE IF NOT EXISTS eBay_items (seller_name TEXT, seller_score REAL, item_price INTEGER,\n",
    "                qty_sold INTEGER, best_offer_available BLOB, title TEXT, returns_allowed BLOB, shipping_computed BLOB,\n",
    "                condition TEXT, sponsor TEXT)\"\"\"\n",
    "# execute sql query\n",
    "cursor.execute(create_table)\n",
    "# Commits the change and close the connection to the database\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "conn = sqlite3.connect('eBay.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "for i in range(len(seller_name_list)):\n",
    "\n",
    "    ### sql commend to insert values to the table\n",
    "    query = \"INSERT INTO eBay_items VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "    cur.execute(query, (seller_name_list[i], seller_scores[i], item_prices[i], qty_sold[i], best_offer_available_list[i], title_list[i], \n",
    "                        returns_allowed_list[i], shipping_computed_list[i], condition_list[i], sponsor_list[i]))\n",
    "### print out sql table content\n",
    "cur.execute(\"SELECT * FROM eBay_items\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)      \n",
    "\n",
    "# commit changes and close database\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Use code script to run summary stats on each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seller_score MIN\n",
      "('NO', 'New', 4.6)\n",
      "('NO', 'Open box', 5.0)\n",
      "('NO', 'Seller refurbished', 4.8)\n",
      "('NO', 'Used', 4.5)\n",
      "('YES', 'New', 4.7)\n",
      "('YES', 'Seller refurbished', 4.8)\n",
      "('YES', 'Used', 4.5)\n",
      "--------------------------------------\n",
      "seller_score MAX\n",
      "('NO', 'New', 5.0)\n",
      "('NO', 'Open box', 5.0)\n",
      "('NO', 'Seller refurbished', 4.8)\n",
      "('NO', 'Used', 4.9)\n",
      "('YES', 'New', 5.0)\n",
      "('YES', 'Seller refurbished', 4.8)\n",
      "('YES', 'Used', 4.8)\n",
      "--------------------------------------\n",
      "seller_score MEAN\n",
      "('NO', 'New', 4.845454545454545)\n",
      "('NO', 'Open box', 5.0)\n",
      "('NO', 'Seller refurbished', 4.8)\n",
      "('NO', 'Used', 4.736363636363635)\n",
      "('YES', 'New', 4.844444444444444)\n",
      "('YES', 'Seller refurbished', 4.8)\n",
      "('YES', 'Used', 4.72)\n",
      "--------------------------------------\n",
      "item_price MIN\n",
      "('NO', 'New', 26211)\n",
      "('NO', 'Open box', 30000)\n",
      "('NO', 'Seller refurbished', 20000)\n",
      "('NO', 'Used', 14000)\n",
      "('YES', 'New', 26200)\n",
      "('YES', 'Seller refurbished', 25300)\n",
      "('YES', 'Used', 7998)\n",
      "--------------------------------------\n",
      "item_price MAX\n",
      "('NO', 'New', 60000)\n",
      "('NO', 'Open box', 30000)\n",
      "('NO', 'Seller refurbished', 20000)\n",
      "('NO', 'Used', 30000)\n",
      "('YES', 'New', 59999)\n",
      "('YES', 'Seller refurbished', 25300)\n",
      "('YES', 'Used', 31500)\n",
      "--------------------------------------\n",
      "item_price MEAN\n",
      "('NO', 'New', 37906.0)\n",
      "('NO', 'Open box', 30000.0)\n",
      "('NO', 'Seller refurbished', 20000.0)\n",
      "('NO', 'Used', 22036.272727272728)\n",
      "('YES', 'New', 39898.555555555555)\n",
      "('YES', 'Seller refurbished', 25300.0)\n",
      "('YES', 'Used', 23059.6)\n",
      "--------------------------------------\n",
      "qty_sold MIN\n",
      "('NO', 'New', 2)\n",
      "('YES', 'New', 2)\n",
      "--------------------------------------\n",
      "qty_sold MAX\n",
      "('NO', 'New', 2)\n",
      "('YES', 'New', 4)\n",
      "--------------------------------------\n",
      "qty_sold MEAN\n",
      "('NO', 'New', 2.0)\n",
      "('YES', 'New', 3.0)\n",
      "--------------------------------------\n",
      "best_offer_available MIN\n",
      "('NO', 'New', 0)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 0)\n",
      "('NO', 'Used', 0)\n",
      "('YES', 'New', 0)\n",
      "('YES', 'Seller refurbished', 1)\n",
      "('YES', 'Used', 0)\n",
      "--------------------------------------\n",
      "best_offer_available MAX\n",
      "('NO', 'New', 1)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 0)\n",
      "('NO', 'Used', 1)\n",
      "('YES', 'New', 1)\n",
      "('YES', 'Seller refurbished', 1)\n",
      "('YES', 'Used', 1)\n",
      "--------------------------------------\n",
      "best_offer_available MEAN\n",
      "('NO', 'New', 0.36363636363636365)\n",
      "('NO', 'Open box', 1.0)\n",
      "('NO', 'Seller refurbished', 0.0)\n",
      "('NO', 'Used', 0.8181818181818182)\n",
      "('YES', 'New', 0.3333333333333333)\n",
      "('YES', 'Seller refurbished', 1.0)\n",
      "('YES', 'Used', 0.6)\n",
      "--------------------------------------\n",
      "returns_allowed MIN\n",
      "('NO', 'New', 0)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 1)\n",
      "('NO', 'Used', 0)\n",
      "('YES', 'New', 0)\n",
      "('YES', 'Seller refurbished', 0)\n",
      "('YES', 'Used', 0)\n",
      "--------------------------------------\n",
      "returns_allowed MAX\n",
      "('NO', 'New', 1)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 1)\n",
      "('NO', 'Used', 1)\n",
      "('YES', 'New', 1)\n",
      "('YES', 'Seller refurbished', 0)\n",
      "('YES', 'Used', 0)\n",
      "--------------------------------------\n",
      "returns_allowed MEAN\n",
      "('NO', 'New', 0.2727272727272727)\n",
      "('NO', 'Open box', 1.0)\n",
      "('NO', 'Seller refurbished', 1.0)\n",
      "('NO', 'Used', 0.36363636363636365)\n",
      "('YES', 'New', 0.5555555555555556)\n",
      "('YES', 'Seller refurbished', 0.0)\n",
      "('YES', 'Used', 0.0)\n",
      "--------------------------------------\n",
      "shipping_computed MIN\n",
      "('NO', 'New', 1)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 1)\n",
      "('NO', 'Used', 1)\n",
      "('YES', 'New', 1)\n",
      "('YES', 'Seller refurbished', 1)\n",
      "('YES', 'Used', 1)\n",
      "--------------------------------------\n",
      "shipping_computed MAX\n",
      "('NO', 'New', 1)\n",
      "('NO', 'Open box', 1)\n",
      "('NO', 'Seller refurbished', 1)\n",
      "('NO', 'Used', 1)\n",
      "('YES', 'New', 1)\n",
      "('YES', 'Seller refurbished', 1)\n",
      "('YES', 'Used', 1)\n",
      "--------------------------------------\n",
      "shipping_computed MEAN\n",
      "('NO', 'New', 1.0)\n",
      "('NO', 'Open box', 1.0)\n",
      "('NO', 'Seller refurbished', 1.0)\n",
      "('NO', 'Used', 1.0)\n",
      "('YES', 'New', 1.0)\n",
      "('YES', 'Seller refurbished', 1.0)\n",
      "('YES', 'Used', 1.0)\n",
      "--------------------------------------\n",
      "('NO', 'New', 11, 11)\n",
      "('NO', 'Open box', 1, 1)\n",
      "('NO', 'Seller refurbished', 1, 1)\n",
      "('NO', 'Used', 11, 11)\n",
      "('YES', 'New', 9, 9)\n",
      "('YES', 'Seller refurbished', 1, 1)\n",
      "('YES', 'Used', 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# connect to the database\n",
    "conn = sqlite3.connect('eBay.db')\n",
    "cur=conn.cursor()\n",
    "\n",
    "# convert boolean data to 0 or 1\n",
    "query_update_offer = \"UPDATE eBay_items SET best_offer_available = CASE WHEN best_offer_available = 'YES' THEN 1 ELSE 0 END\"\n",
    "cur.execute(query_update_offer)\n",
    "\n",
    "query_update_return = \"UPDATE eBay_items SET returns_allowed = CASE WHEN returns_allowed = 'YES' THEN 1 ELSE 0 END\"\n",
    "cur.execute(query_update_return)\n",
    "\n",
    "query_update_shipping = \"UPDATE eBay_items SET shipping_computed = CASE WHEN shipping_computed = 'YES' THEN 1 ELSE 0 END\"\n",
    "cur.execute(query_update_shipping)\n",
    "\n",
    "# sql queries to calculate stats for each column, and print the results out\n",
    "columns = ['seller_score', 'item_price', 'qty_sold', 'best_offer_available', 'returns_allowed', 'shipping_computed']\n",
    "for col in columns:\n",
    "    \n",
    "    print(col + ' MIN')\n",
    "    query_min = \"SELECT sponsor, condition, MIN(\" + str(col) + \") FROM eBay_items WHERE \" + str(col) + \" IS NOT NULL GROUP BY sponsor, condition;\"\n",
    "    cur.execute(query_min)\n",
    "    result_min = cur.fetchall()\n",
    "    for row in result_min:\n",
    "        print(row)\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    print(col + \" MAX\")\n",
    "    query_max = \"SELECT sponsor, condition, MAX(\" + str(col)+ \") FROM eBay_items WHERE \" + str(col)+ \" IS NOT NULL GROUP BY sponsor, condition;\"\n",
    "    cur.execute(query_max)\n",
    "    result_max = cur.fetchall()\n",
    "    for row in result_max:\n",
    "        print(row)\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    print(col + \" MEAN\")\n",
    "    query_mean = \"SELECT sponsor, condition, AVG(\" + str(col)+ \") FROM eBay_items WHERE \" + str(col)+ \" IS NOT NULL GROUP BY sponsor, condition;\"\n",
    "    cur.execute(query_mean)\n",
    "    result_mean = cur.fetchall()\n",
    "    for row in result_mean:\n",
    "        print(row)\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "query_count = \"SELECT sponsor, condition, COUNT(seller_name), COUNT(title) from eBay_items GROUP BY sponsor, condition;\"\n",
    "cur.execute(query_count)\n",
    "result_count = cur.fetchall()\n",
    "for row in result_count:\n",
    "    print(row)\n",
    "\n",
    "# commit changes and close database\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
